# Задание
Реализовать API с использованием которое позволит удалять данные из реляционной БД таблиц объемом 10 млн строк и более. 
Ключ, по которому производится удаление данных, столбец DateTime (удаляем старые данные). Работа системы не должна 
приводить к длительным блокировкам данных. АPI может вызываться несколькими внешними процессами одновременно. 
(1 процесс удаляет данные в 1 таблице). Необходимо обеспечить логирование работы API.

# Решение
Задание реализовано в кач-ве приложения асинхронно выполняющего задачи на удаление старых данных и предоставляющего REST API.

Алгоритм работы приложения:
1. Пользователь размещает запрос на удаление старых данных и получает в ответ идентификатор отложенного задания
2. Приложение последовательно в фоне удаляет записи небольшими порциями заданного размера
3. Пользователю предоставляются дополнительные методы для уточнения текущего статуса задания и его отмены

## Запуск
### Окружение
Для работы приложения потребуется подключение к `postgres`. Настройки подключения указываются в файле `application.yml`.
В составе репозитория предоставляется `docker-compose` файл, разворачивающий инстанс
`postgres` в docker контейнере с предсозданной таблицей с данными `data.big_table`.

Пример запуска docker-compose:\
`docker-compose up -d`

### Приложение
Запустить приложение можно выполнив main метод класса `com.test.datarecycler.Application`. По умолчанию приложение
использует порт `8080`.

## Использование
### Создание задачи на удаление данных
Эндпоинт: `[POST] /api/v1.0/data/recycler/job`

**Пример запроса:**
```
curl --location --request POST 'http://127.0.0.1:8080/api/v1.0/data/recycler/job' \
--header 'Content-Type: application/json' \
--data-raw '{
    "table_name" : "data.big_table",
    "datetime_field_name" : "ts",
    "older_than" : "2021-04-26T11:11:30.985328Z"
}'
```
Где:
  - `table_name` - название таблицы для удаления данных
  - `datetime_field_name` - название столбца с датой-временем
  - `older_than` - временная метка, относительно которой будет выполняться удаление

**Пример успешного ответа:**
```
< HTTP/1.1 204 
< Content-Type: application/json;charset=UTF-8
{
    "job_id": "3af3d984-c82a-46c2-99fe-eb20f3a3ca70"
}
```
Где
- `job_id` - идентификатор созданной задачи

**Пример неуспешно ответа:**
```
< HTTP/1.1 409 
< Content-Type: application/json;charset=UTF-8
{
    "status": 409,
    "messages": [
        "Job for table 'data.big_table' already exists: 661ae2f1-33cc-4f5a-aa7d-e65e0995efe7"
    ]
}
```

### Просмотр состояния задачи
Эндпоинт: `[GET] /api/v1.0/data/recycler/job/:jobId`

**Пример запроса:**
```
curl --location --request GET 'http://127.0.0.1:8080/api/v1.0/data/recycler/job/3af3d984-c82a-46c2-99fe-eb20f3a3ca70'
```

**Пример успешного ответа:**
```
< HTTP/1.1 200 
< Content-Type: application/json;charset=UTF-8
{
    "state": "RUNNING",
    "deleted_count": 8000
}
```
Где
- `state` - статус текущий задачи. Возможные значения: PENDING, RUNNING, FINISHED, CANCELLED, FAILED.
- `deleted_count` - кол-во удаленных строк, изменяется по мере выполнения задачи

**Пример неуспешного ответа:**
```
< HTTP/1.1 404
< Content-Type: application/json;charset=UTF-8
{
    "status": 404,
    "messages": [
        "Job with id '3af3d984-c82a-46c2-99fe-eb20f3a3ca70' not found"
    ]
}
```

### Отмена задачи
Эндпоинт: `[DELETE] /api/v1.0/data/recycler/job/:jobId`

**Пример запроса:**
```
curl --location --request DELETE 'http://127.0.0.1:8080/api/v1.0/data/recycler/job/3af3d984-c82a-46c2-99fe-eb20f3a3ca70'
```

**Пример успешного ответа:**
```
< HTTP/1.1 204
< Content-Type: application/json;charset=UTF-8
{
    "state": "CANCELLED",
    "deleted_count": 8000
}
```

**Пример неуспешного ответа:**
```
< HTTP/1.1 404
< Content-Type: application/json;charset=UTF-8
{
    "status": 404,
    "messages": [
        "Job with id '3af3d984-c82a-46c2-99fe-eb20f3a3ca70' not found"
    ]
}
```


## Комментарии к реализации
Лучший вариант для удаления старых данных использование партиционирования по дате. При таком подходе удаление
сводится к дропу старых партиций, но не позволяет удалять данные от произвольной точки во времени.
Другой вариант - удалять небольшими порциями через `delete`. К сожалению, такой способ может занимать достаточно много 
времени и не хотелось бы блокировать клиента вызывающего API на этот период. По этой причине задание было
реализовано как сервис выполняющий асинхронные задачи на удаление. Для простоты текущая реализация использует локальную 
оперативную память для хранения очереди задач и их состояния. Такой подход не позволяет говорить о резервировании и 
какой либо отказоустойчивости. При реализации аналогичного задания для реального использования необходимо смотреть 
в сторону вынесения очереди задач и их состояния в сторонние зарезервированные хранилища. Например, для хранения 
состояния задач подойдет Redis. Сами задачи имеет смысл передавать на исполнение через специализированную очередь, 
напрмер RabbitMQ. Структура кода приложения подразумевает легкий переход к описанному варианту за счет замены реализаций
интерфейсов `RecycleJobRepository` и `RecycleJobExecutor`.